{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Our Custom Models üèãÔ∏è\n",
    "- in this notebook we train and test our custom implementations of Deep Speech 2, Jasper, and Conformer\n",
    "- the models take as input Mel Filterbanks (2D images) and output probability distribution over characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/5 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Custom libraries\n",
    "from utils.preprocessing import Preprocessing\n",
    "from utils.word_model import WordModel\n",
    "from utils.decoders import DecoderGreedy\n",
    "from utils.metrics import avg_cer, avg_wer\n",
    "from utils.misc import pretty_params\n",
    "\n",
    "# Plots\n",
    "import wandb\n",
    "\n",
    "# Models\n",
    "from models.deep_speech.deep_speech_base import DeepSpeechBase\n",
    "from models.deep_speech.deep_speech_attention import DeepSpeechAttention\n",
    "from models.jasper.jasper_base import Jasper\n",
    "from models.jasper.jasper_dr import JasperDR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "- to use unigrams: set `WordModel(\"unigram\")` and `stride=2`\n",
    "- to use bigrams: set `WordModel(\"bigrams\")` and `stride=4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Hyper-params\n",
    "seed = 42\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "n_features = 128            # freq axis\n",
    "stride = 2                  # time-axis striding\n",
    "\n",
    "word_model = WordModel(\"unigram\")\n",
    "lr = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Speech Hyper-params\n",
    "stage_1 = 3                 # 1st stage\n",
    "stage_2 = 12                 # 2nd stage\n",
    "\n",
    "rnn_dim = 512               # for DeepSpeechBase\n",
    "emb_dim = 512               # for DeepSpeechAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/5 Data processing\n",
    "- set `download=True` if you are downloading for the first time\n",
    "- we donwload the train set (`train-clean-100`), dev set (`dev-clean` and `dev-other`), and test set (`test-clean` and `test-other`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\.conda\\envs\\exp\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prep = Preprocessing()\n",
    "\n",
    "train_clean = prep.download(split='train-clean-100', download=False)\n",
    "\n",
    "dev_clean = prep.download(split='dev-clean', download=False)\n",
    "dev_other = prep.download(split='dev-other', download=False)\n",
    "\n",
    "test_clean = prep.download(split='test-clean', download=False)\n",
    "test_other = prep.download(split='test-other', download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_clean,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=lambda x: prep.preprocess(x, \"train-clean-100\", stride, word_model))\n",
    "\n",
    "dev_clean_loader = DataLoader(dataset=dev_clean,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               collate_fn=lambda x: prep.preprocess(x, \"dev-clean\", stride, word_model))\n",
    "\n",
    "dev_other_loader = DataLoader(dataset=dev_other,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               collate_fn=lambda x: prep.preprocess(x, \"dev-other\", stride, word_model))\n",
    "\n",
    "test_clean_loader = DataLoader(dataset=test_clean,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               collate_fn=lambda x: prep.preprocess(x, \"test-clean\", stride, word_model))\n",
    "\n",
    "test_other_loader = DataLoader(dataset=test_other,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               collate_fn=lambda x: prep.preprocess(x, \"test-other\", stride, word_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ TRAIN \t28539 samples ~\n",
      "~ DEV CLEAN \t2703 samples ~\n",
      "~ DEV OTHER \t2864 samples ~\n",
      "~ TEST CLEAN \t2620 samples ~\n",
      "~ TEST OTHER \t2939 samples ~\n",
      "+------ Dataloader length: 28539 ------+\n",
      "# Batches: 1784\n",
      "Spectrogram shape: [16, 1, 128, 1308]\n",
      "Label shape: [16, 257]\n",
      "Mel length (length of each spectrogram): [577, 654, 300, 484, 542, 584] ...\n",
      "Idx length (length of each label): [197, 257, 121, 173, 196, 205] ...\n",
      "+------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "## Sanity check ##\n",
    "\n",
    "print(f\"~ TRAIN \\t{len(train_loader.dataset)} samples ~\")\n",
    "print(f\"~ DEV CLEAN \\t{len(dev_clean_loader.dataset)} samples ~\")\n",
    "print(f\"~ DEV OTHER \\t{len(dev_other_loader.dataset)} samples ~\")\n",
    "print(f\"~ TEST CLEAN \\t{len(test_clean_loader.dataset)} samples ~\")\n",
    "print(f\"~ TEST OTHER \\t{len(test_other_loader.dataset)} samples ~\")\n",
    "\n",
    "prep.print_loader_info(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/5 Model\n",
    "Available models:\n",
    "\n",
    "- DeepSpeech-Base\n",
    "- DeepSpeech-Attention\n",
    "- Jasper-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 56.79M (56792861)\n"
     ]
    }
   ],
   "source": [
    "# DeepSpeechBase\n",
    "deep_speech = DeepSpeechBase(n_cnn=stage_1,\n",
    "                             n_rnn=stage_2, \n",
    "                             rnn_dim=rnn_dim, \n",
    "                             n_features=n_features, \n",
    "                             n_class=word_model.get_n_class(),\n",
    "                             stride=stride,\n",
    "                             drop_rate=0.2).to(device)\n",
    "\n",
    "tot_params = sum([p.numel() for p in deep_speech.parameters()])\n",
    "model_name=\"deep_speech_base\"\n",
    "print(f\"Number of parameters: {pretty_params(tot_params)} ({tot_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 20.32M (20319005)\n"
     ]
    }
   ],
   "source": [
    "# DeepSpeechAttention\n",
    "deep_speech = DeepSpeechAttention(n_cnn=stage_1,\n",
    "                                  n_enc=stage_2,\n",
    "                                  n_features=n_features,\n",
    "                                  n_class=word_model.get_n_class(),\n",
    "                                  emb_dim=emb_dim,\n",
    "                                  n_heads=4,\n",
    "                                  stride=stride,\n",
    "                                  drop_rate=0.2).to(device)\n",
    "\n",
    "tot_params = sum([p.numel() for p in deep_speech.parameters()])\n",
    "model_name=\"deep_speech_attention\"\n",
    "print(f\"Number of parameters: {pretty_params(tot_params)} ({tot_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 107.87M (107873693)\n"
     ]
    }
   ],
   "source": [
    "# JasperBase\n",
    "jasper = Jasper().to(device)\n",
    "\n",
    "tot_params = sum([p.numel() for p in jasper.parameters()])\n",
    "model_name=\"jasper_base\"\n",
    "print(f\"Number of parameters: {pretty_params(tot_params)} ({tot_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 109.91M (109908125)\n"
     ]
    }
   ],
   "source": [
    "# Jasper DR (Dense Residual)\n",
    "jasper = JasperDR().to(device)\n",
    "\n",
    "tot_params = sum([p.numel() for p in jasper.parameters()])\n",
    "model_name=\"jasper_DR\"\n",
    "print(f\"Number of parameters: {pretty_params(tot_params)} ({tot_params})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DecoderGreedy(word_model.get_blank_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/5 Optimizer, loss, scheduler\n",
    "- set here the model you want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_train = deep_speech\n",
    "# model_to_train = jasper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optionally, load model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path_to_weights = \"./weights/jasper_base_lr_variable.pth\"\n",
    "path_to_weights = \"./weights/3invres_12attention.pth\"\n",
    "model_to_train.load_state_dict(torch.load(path_to_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change model\n",
    "adamW = optim.AdamW(model_to_train.parameters(), lr)\n",
    "ctc_loss = nn.CTCLoss(blank=word_model.get_blank_id()).to(device)\n",
    "one_cycle_lr = optim.lr_scheduler.OneCycleLR(adamW,\n",
    "                                             max_lr=lr,\n",
    "                                             steps_per_epoch=int(len(train_loader)),\n",
    "                                             epochs=epochs,\n",
    "                                             anneal_strategy=\"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5/5 Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online fancy plots\n",
    "! wandb login\n",
    "\n",
    "wandb.init(\n",
    "    project=\"asr_librispeech\",\n",
    "\n",
    "    config= {\n",
    "        \"model\": model_name,\n",
    "        \"word_model\": word_model.get_name()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training info\n",
    "- After the forward pass, output must be  `[batch_size, seq_len, n_class]`\n",
    "- CTC loss expects predictions to be `[seq_len, batch_size, n_class]`\n",
    "- Train your model for `epochs` number of epochs\n",
    "- At the end of each epoch, get WER/CER on validation/test dataset\n",
    "\n",
    "Deep Speech\n",
    "- Works with 3D inputs, so leave `squeeze=False`\n",
    "- Outputs Tensors with shape `[batch_size, seq_len, n_class]`, so leave `swap_dim=False`\n",
    "\n",
    "Jasper\n",
    "- Jasper takes 2D Tensors instead of 3D, so set `squeeze=True`\n",
    "- It also outputs predictions with shape `[batch_size, n_class, seq_len]`, so set `swap_dim=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, dataset_loader, model, optimizer, scheduler, fn_loss, \n",
    "          squeeze=False, swap_dim=False):\n",
    "    print(f\"Traininig... (e={epoch})\")\n",
    "    \n",
    "    # Train mode ON\n",
    "    model.train()\n",
    "    n_samples = int(len(dataset_loader.dataset))\n",
    "\n",
    "    for idx, audio_data in enumerate(dataset_loader):\n",
    "        \n",
    "        # Get audio data\n",
    "        spectrograms, indices, len_spectrograms, len_indices = audio_data\n",
    "        spectrograms, indices = spectrograms.to(device), indices.to(device)\n",
    "\n",
    "        if squeeze:\n",
    "            spectrograms = spectrograms.squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        out = model(spectrograms)\n",
    "\n",
    "        if swap_dim:\n",
    "            out = out.transpose(1, 2)\n",
    "        \n",
    "        out = F.log_softmax(out, dim=2)\n",
    "        out = out.transpose(0, 1)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss = fn_loss(out, indices, len_spectrograms, len_indices)\n",
    "        loss.backward()\n",
    "\n",
    "        # Log\n",
    "        wandb.log({\n",
    "            \"loss\": loss.item(),\n",
    "            \"lr\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "        # Step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Log\n",
    "        if idx % 20 == 0 or idx == n_samples:\n",
    "            print(\"Epoch: {}, [{}/{}], Loss: {:.6f}\".format(\n",
    "                epoch, \n",
    "                idx*len(spectrograms), \n",
    "                n_samples,\n",
    "                loss.item()))\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, dataset_name, dataset_loader, model, optimizer, fn_loss, \n",
    "         debug=False, squeeze=False, swap_dim=False):\n",
    "    print(f\"Testing on {dataset_name} (epoch={epoch})\")\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    wer_list = []\n",
    "    cer_list = []\n",
    "\n",
    "    n_batch = int(len(dataset_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, audio_data in enumerate(dataset_loader):\n",
    "        \n",
    "            # Get audio data\n",
    "            spectrograms, indices, len_spectrograms, len_indices = audio_data\n",
    "            spectrograms, indices = spectrograms.to(device), indices.to(device)\n",
    "\n",
    "            if squeeze:\n",
    "                spectrograms = spectrograms.squeeze()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(spectrograms)\n",
    "\n",
    "            if swap_dim:\n",
    "                out = out.transpose(1, 2)\n",
    "\n",
    "            out = F.log_softmax(out, dim=2)\n",
    "            out = out.transpose(0, 1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = fn_loss(out, indices, len_spectrograms, len_indices)\n",
    "            total_loss += loss.item() / n_batch\n",
    "\n",
    "            # Metrics\n",
    "            decode_hypothesis = decoder.decode_prob(out, word_model)\n",
    "            decode_reference = decoder.decode_labels(indices, len_indices, word_model)\n",
    "\n",
    "            wer_list.append(avg_wer(decode_hypothesis, decode_reference))\n",
    "            cer_list.append(avg_cer(decode_hypothesis, decode_reference))\n",
    "            \n",
    "            if idx % 20 == 0:\n",
    "                print(f'Idx: {idx}')\n",
    "                print(f'reference: {decode_reference[0]}')\n",
    "                print(f'hypothesis: {decode_hypothesis[0]}')\n",
    "                print(f\"WER: {wer_list[-1]:.4f}, CER: {cer_list[-1]:.4f}\")\n",
    "                print()\n",
    "\n",
    "            if debug: break\n",
    "            \n",
    "    print(f\"Loss: {total_loss:.6f}\")\n",
    "    print(f\"WER: {sum(wer_list)/len(wer_list):.4f}\")\n",
    "    print(f\"CER: {sum(cer_list)/len(cer_list):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch, train_loader, model_to_train, adamW, one_cycle_lr, ctc_loss, squeeze=True, swap_dim=True)\n",
    "    test(epoch, \"dev-clean\", dev_clean_loader, model_to_train, adamW, ctc_loss, squeeze=True, swap_dim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "- pick the split you want to get your metrics on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(1, \"dev-clean\", dev_clean_loader, model_to_train, adamW, ctc_loss, squeeze=False, swap_dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(1, \"dev-other\", dev_other_loader, model_to_train, adamW, ctc_loss, squeeze=True, swap_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(1, \"test-clean\", test_clean_loader, model_to_train, adamW, ctc_loss, squeeze=True, swap_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(1, \"test-other\", test_other_loader, jasper, adamW, ctc_loss, squeeze=True, swap_dim=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
